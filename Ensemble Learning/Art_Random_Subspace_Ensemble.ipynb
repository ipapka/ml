{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Subspace Ensemble for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.856 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# evaluate random subspace ensemble via bagging for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the random subspace ensemble model\n",
    "model = BaggingClassifier(bootstrap=False, max_features=10)\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make predictions using random subspace ensemble via bagging for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the model\n",
    "model = BaggingClassifier(bootstrap=False, max_features=10)\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[-4.7705504,-1.88685058,-0.96057964,2.53850317,-6.5843005,3.45711663,-7.46225013,2.01338213,-0.45086384,-1.89314931,-2.90675203,-0.21214568,-0.9623956,3.93862591,0.06276375,0.33964269,4.0835676,1.31423977,-2.17983117,3.1047287]]\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "# define the ecoc model\n",
    "ecoc = OutputCodeClassifier(model1, code_size=2, random_state=1)\n",
    "\n",
    "# make predictions using random subspace ensemble via bagging for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the model\n",
    "model = BaggingClassifier(base_estimator=ecoc, bootstrap=False, max_features=10)\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[-4.7705504,-1.88685058,-0.96057964,2.53850317,-6.5843005,3.45711663,-7.46225013,2.01338213,-0.45086384,-1.89314931,-2.90675203,-0.21214568,-0.9623956,3.93862591,0.06276375,0.33964269,4.0835676,1.31423977,-2.17983117,3.1047287]]\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.895 (0.031)\n"
     ]
    }
   ],
   "source": [
    "# evaluate random subspace ensemble via bagging for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "\n",
    "model1 = SVC()\n",
    "# define the ecoc model\n",
    "ecoc = OutputCodeClassifier(model1, code_size=5, random_state=1)\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the random subspace ensemble model\n",
    "model = BaggingClassifier(base_estimator=ecoc, bootstrap=False, max_features=10)\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Subspace Ensemble for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -115.003 (12.379)\n"
     ]
    }
   ],
   "source": [
    "# evaluate random subspace ensemble via bagging for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=5)\n",
    "# define the model\n",
    "model = BaggingRegressor(bootstrap=False, max_features=10)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -157\n"
     ]
    }
   ],
   "source": [
    "# random subspace ensemble via bagging for making predictions for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=5)\n",
    "# define the model\n",
    "model = BaggingRegressor(bootstrap=False, max_features=10)\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[0.88950817,-0.93540416,0.08392824,0.26438806,-0.52828711,-1.21102238,-0.4499934,1.47392391,-0.19737726,-0.22252503,0.02307668,0.26953276,0.03572757,-0.51606983,-0.39937452,1.8121736,-0.00775917,-0.02514283,-0.76089365,1.58692212]]\n",
    "yhat = model.predict(row)\n",
    "print('Prediction: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -99.144 (13.003)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "\n",
    "# evaluate random subspace ensemble via bagging for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=5)\n",
    "# define the model\n",
    "model = BaggingRegressor(base_estimator=regressor, bootstrap=False, max_features=10)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -58.252 (5.237)\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = regressor\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Subspace Ensemble Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.858 (0.033)\n",
      ">50 0.875 (0.041)\n",
      ">100 0.891 (0.036)\n",
      ">500 0.892 (0.034)\n",
      ">1000 0.897 (0.035)\n",
      ">5000 0.895 (0.034)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore random subspace ensemble number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tn_trees = [10, 50, 100, 500, 1000, 5000]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n, bootstrap=False, max_features=10)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.611 (0.045)\n",
      ">2 0.775 (0.043)\n",
      ">3 0.834 (0.042)\n",
      ">4 0.867 (0.036)\n",
      ">5 0.868 (0.038)\n",
      ">6 0.887 (0.034)\n",
      ">7 0.887 (0.034)\n",
      ">8 0.888 (0.040)\n",
      ">9 0.891 (0.039)\n",
      ">10 0.893 (0.036)\n",
      ">11 0.891 (0.037)\n",
      ">12 0.885 (0.042)\n",
      ">13 0.881 (0.039)\n",
      ">14 0.877 (0.040)\n",
      ">15 0.870 (0.043)\n",
      ">16 0.859 (0.039)\n",
      ">17 0.853 (0.040)\n",
      ">18 0.828 (0.045)\n",
      ">19 0.818 (0.049)\n",
      ">20 0.802 (0.050)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAd80lEQVR4nO3df5Ac5X3n8fd3VwKB+eFdVtwZBEhJYWpZJf7BhthnBWftkAKSEjGOKXRxypTlo0gFxXYuOFBLsJBq65wEX3y1RXmLsJxzTrQYE5CUFObHWetwugOHBUtYsMaWMYQ1GC2gmGAiWLPf+6N7xOxofnT39M70PPt5VU3t/Oh++pnenu888336edrcHRER6Xxd7a6AiIjkQwFdRCQQCugiIoFQQBcRCYQCuohIIJa1a8N9fX2+evXqdm1eRKQjPfLIIy+6+8pqr7UtoK9evZqpqal2bV5EpCOZ2TO1XlPKRUQkEAroIiKBUEAXEQmEArqISCAU0EVEAqGALiISCAV0EZFAKKCLiASibQOLZGkxsyOe01z8IvlSQJeWKAVvM1MgF1kkSrmIiARCAV1EJBAK6CIigVAOXZYMdcxK6BTQZclQx6yETikXEZFAKKCLiARCKZfA5ZE3LkLuuQh1KFI9RKpRQA9cHnnjIuSei1CHItVDpBqlXEREAqGALiISCKVcFpHyrVKp2jEB6Y4LHVdSiwL6IlK+VSqVHwdZjwsdV1KLUi4iIoFQQBcRCYQCuohIIBTQC8zMjrhJer29vUfsw/LHvb29ba5h6+VxbOn4LB51ihaYOr/ycfDgwbr7bykGolAGnMlCaqGLiARCAV1EJBAK6DUoPyjlms3DV66vXL4sBuXQa1B+sBh6e3s5ePDggucqv1x7enp4+eWXF7UezebhG62fpAyRRhTQpdAUCEWSU8pFRCQQCugiIoFQQA9UHoNp1BFYLI3+H9qf2YQ0yCpRDt3MLgD+B9AN3OLuX6h4/QzgVmAl8DLwcXefybmukkIeg2nUEVgseezPRp3MrehgLpqQBlk1bKGbWTdwE3AhcDawwczOrljsRuB/ufsvA1uA/5Z3RUWkeaUvhVq3ymAvnSVJyuVcYL+7P+XubwC3ARdXLHM28M34/mSV10VEZJElSbmcCjxb9ngG+NWKZfYCHyVKy3wEON7MTnL3l8oXMrMrgCsATj/99Kx1lg7hnz8BNp/YeJlFLqPc7GuzXP3A1dz4wRvpO6Yv8XrylrzSNrp60yKo9/Mr3jEfI8qblx7/PjBascwpwJ3Ad4iC+gxwYr1yzznnHO8E0S5qbRk9PT0O1L319PQ0tc0kdWq2jLy3ceBnB/wT3/iEz742m7mMLQ9u8V/6yi/51ge3Zq5ntXoUYX/nUUar6pnHOnmuX6QyEmxjymvE1SQplxngtLLHq4DnKr4UnnP3S9z9PcBw/NxPE5QtVTTKc3qH5jpnX5vl8nsu58V/fzHT+mOPjfHoC48ytncs8/Z37N+B42zfv71t9RBZLEkC+sPAmWa2xsyOAi4DdpYvYGZ9ZlYq61qiM16kIJoNpHmV0UwgzCMYjz02xrzPAzDv822rR6mcZvenSCXzBPkmM7sI+BLRaYu3uvuImW0havrvNLPfJTqzxYEHgD9099frlTk4OOhTU1NNv4HFlvY0pGr5xUqNcoxJttlwmbK889aTevj68cdx6b+9ynUvldVtc4MfUU2WUV7H2ddmufDOC3n9zdc5uvto7vnoPfQd09fwfZRe3/rQVu76wV3Mzc+xvGs5l5x5Cde977ojtlPrfcx2d3HhqlN4veutNszR8/PcM/McfW/OJ94XW0/q4a7jjmOuy1g+71zyatn+SLgvALY+tJWvP/l1Lj3r0sTvI4/jogjbyOMzknabnVRGgm084u6DVV9b7I3XEmpAb8UHIk0ZWQNpHmWUv14rICcp48DPDhzefknaemx5cMvh7ZeU6vFn7/+zRPuiXj1WHrsy8b7IY3/W6tzthICeS4OlyeWLXEaCbdQM6BopGrg80gzNllFKU5SC6dz8XKp0Rfn2S9LWY++BvQuCeakeew7sSVxGHvWoLKeZ/4ny+FJJsy0GrFYgvfJdV7a0jGYDYR7B+I71d9R8zUg2WrWZepROv5zt7mLHqlOYi1M/c/NzbJ+e4Mr7v5j4FM5SGd7VdXjdvjfn31omIZ3CGR4F9IDl0aIsQuu4XjBupWa+FOyGV3B3xh7ayvwP7oKy/TG/7GjGzv+vUepnc7oySusuyMPXKaNceSu/tL50NgX0gOXRsi1K6zgUze7Per+YkrSyG7Xyk7TwGw32SvMrIavQ5qTJY5AVBNopOjExwcjICNPT0/T39zM8PMyGDRsyldXpnaKhb6NT6pnXNup17ibtZK531lDaelZL23TK/s5jnXaUsaQ6RScmJhgeHmZ0dJRDhw4xOjrK8PAwExMTbalPs+cb63xlKZfHL6ZmO6nLqXO2WIJLuYyMjDA+Ps7Q0BAAQ0NDjI+Ps2nTpsyt9GY0m6dUnrPxlLA9PT0tqkn75dGfkNfZOpWDrJKmfWTxBNdCn56eZt26dQueW7duHdPT0y2vS9ZRhYfznFt72DF9W7T+9AQvbu2JcpebT2xJnhKqT9xfurUikFZOeVDtuVblSpvdF/XWb9X+hHxa+ZDP6ZeSr+Ba6P39/ezevftwCx1g9+7d9Pf3t7wu1Q74JK3svM9myKoyj9fuyfvbqdl9UW3Zdu3PPDqp8zidVfIXXAt9eHiYjRs3Mjk5ydzcHJOTk2zcuJHh4eGWbL+ydb3ggI9b2Ula13nmOUXyllfaBtRPlKfgAvqGDRsYGRlh06ZNrFixgk2bNjEyMtKy/Lnd8Aps/ilj5/8x88uOXvBaqZVtN7zSsJw8PzAiecsrbQPqWM1TcCkXiIJ6OzpAyzV7wOf5gRHJW15jC9Sxmq8gz0NvRqOZ4FoxU2JeZdSTZeBFlnPyG2nFrHpF2Bd5lJHH/izCOeKVs3hmmb2yvIzZ7i6uXtnHjbMvHp4CoeH6NP9Zr6bd56EroFcoygASzUZX3DoUpYzFGDzTykE/5bNOlmSZvTLLVMR5vI+81slQr6UzsEhEOkMe/UR5XXAkFAroIktMEc6Fh/ynNNZJA4F2ilbLNS7V86dDUf4/Ld3X/zS9vMYW1MvnJ/1SaLZjtQjnwhdtkrAgA3rpAF3KA2FCo/9jcRRlwFkRTu0tXdC9liQd2XlSykVEOpJO7T1SkC10EQmf5tk/klrodWQdkpzHJExFmcipvC6V95ci7Yt8LPZnZCnNwFlOAb2OLEOSK2cCrDZDYKNOkiLNMFht20s5n6190bxWfEY66WpFeVJAr0Hnt4osHaFMEKaAXoPObxVZOkKZIEwBvQpNXSuydIT0a1wBvYJ//gTGxn+F+blDC56fnzvE2C2DLbtSUF7UiSdSXenaBeWf99LnvFVXBevt7T2iQxcWdvj29vYmLk8BvYLd8Ap7zxhkrmth4JvrMvacMZhoLvMiUSeeSHV2wyvMfm4/O3r6Dn/e57qM7T19vPinP2zJZ700MKnerd6MkJV0HnoVOr9VZGnI+8pLVz9wNTd+8Ma2zemuFrqILFmhXXkp6PnQ2zVfdB7r5Ll+kRThvRShDnnUowhzsheljLZ91uMLbcx2d3HhqlN4vauLo+fnuWfmubcutlHnQhtZ5m3XfOgiIoug2jWES9cOZvNPW97npoAuItKEIp3mrIAuItKEIkzjW6KALiLShCJN46vTFqvI42osItVUHltZrr6Ux9WbilJGCPI8zbnZUx8TtdDN7AIze9LM9pvZNVVeP93MJs3sO2b2mJldlLomBaFZ3I40MTHB2rVr6e7uZu3atUxMTLS7Sh2r1uCRZsvIox7tKEMWavbUx4YtdDPrBm4CzgdmgIfNbKe7P1G22HXA7e7+ZTM7G7gbWJ2pRlIoExMTDA8PMz4+zrp169i9ezcbN24EYMOGDW2unUhnK00/ANGpjztWnYJ3dbF9eoIr7/8ifW/Op5qCIEkL/Vxgv7s/5e5vALcBF1fWCyht9UTgucQ1kEIbGRlhfHycoaEhli9fztDQEOPj44yMjLS7aiJNa/dFMkqnPeZ16mOSgH4q8GzZ45n4uXKbgY+b2QxR63xT1cqbXWFmU2Y2NTs7m7iSnSqEibGmp6dZt27dgufWrVvH9PR0m2qUXQj/j5DUmpCqVYqUXs3r1MckAb3aHq5Mlm0AvuLuq4CLgK+a2RFlu/vN7j7o7oMrV65MVdEkKmcug+yzluUhhBxjf38/u3fvXvDc7t276e/vb1ONssvj/6H+hPzk0Z8QirxOfUwS0GeA08oer+LIlMpG4HYAd38QWAG0fHaaRjOXpZm1TCLDw8Ns3LiRyclJ5ubmmJycZOPGjQwPD7e7ai1X6k8YHR3l0KFDjI6OMjw8rKAuTcvt1MdGUzcSdZw+BawBjgL2AgMVy3wDuDy+308U8K1eueecc47nLXo72V/Pa528tbsO27Zt84GBAe/q6vKBgQHftm1b5rLa/V6aMTAw4Lt27Vrw3K5du3xgYKBNNZKSPI6rrPGh3q2np6fpbVYuA0x5jbiaaHKu+DTELwHdwK3uPmJmW+KCd8Zntvw1cFz8Rj7n7vfVK3MxJucq4sRaeShCHZpVLTfaae+pu7ubQ4cOsXz58sPPzc3NsWLFCt5888021kyKMEFYljLynpwr0cAid7+bqLOz/Lnry+4/AXwgSVmyNHVa8K6m1J8wNDR0+LlO7U+QMGnov0hCRelPUMes1KKh/yIJlQZSbdq0ienpafr7+xkZGWnpACsN9JJ6grrARXmuqdqcCMqhS6dbu3Yto6OjC9I+k5OTbNq0iX379rWxZu2lHHok2JRLES4H1SwNhJFKIQ30ykMIn5F6o1XTjlgNMqCXRl053raJ5vNQ7bQkWdpCGuiVh07/jNSqf/njNCNWgwzo5aOu2jXRvMhiKErHrBRTcJ2iteZEuPJdV7a5ZiLNK0LHrBRXUJ2ibD6RrSf1cNdxxzHX9VYubfm8c8mrr3LdSwfrXoG7GnVIiiwNzXzW8xw4l2CA5NLoFLUbXmHvGYMLgjnAXJex54zBll+BW0SWhqLk8oNLueR5OSgRkU4SVAtdRGQpU0AXEQmEArqISCAU0KUjaEKqfGl/him4TlEJjyakypf2Z8BqXflisW+6YpEkpSsF5Uv7s7qifNYTxLHmrli0GBZrtsV6enp6Es+LEMIVdkKhKwXlS/tzoaJ91jWwKFb5bVX5XJpJbqp9+0l7hDYhVbvz13ntz3a/j7wE9Vmv1XRf7NtipFwqUZCfUNKcbdu2+Zo1a3zXrl3+xhtv+K5du3zNmjVNXay6XYrwXvKoQxHeR6gaxS3qpFwU0KUjbNu2zQcGBryrq8sHBgY6NnAUJX/d7P4syvsIUTMBPagceiVNrCVFE0r+OpT3URS1+v+qxa8lk0MXKbpQ+gNCeR9FUavFnZYCukgLhXKBilDeR2g0sEikhUK5QEUo7yM0yqGLiHQQ5dBFRJYABXQRaZtmByeFMrgpL8qhi0hbNDtJmCYZq6LW6TKLfdPAIpGlrdnBSUt1cBMaWCQiRdPs4KSlOrhJnaIiUjjNDk7SJGNV1Gq6L/ZNKReRpa3ZCb6W6iRjaHIuESmiZicJW4qTjNUL6EHm0Is2Yb2IFFMn5uGXXA692jeXiEil0CYZSxTQzewCM3vSzPab2TVVXv8rM9sT375vZv+af1VFRPKV1yRjeXSs5tI5WysXU9ay7QZ+CPwCcBSwFzi7zvKbgFsblduKHLqISCN55PFb2TlLM52iwPuBe8seXwtcW2f5/wec36hcBXQRCUEeHatpyqgX0Bt2iprZ7wIXuPun4se/D/yqu19VZdkzgIeAVe5+RI+CmV0BXAFw+umnn/PMM89U217NXxIiIkWTR8dqmjKa7RStFmFrRdfLgDuqBXMAd7/Z3QfdfXDlypVVC/C3Wvrq1BSRwsujYzWvztkkAX0GOK3s8SrguRrLXgZ08DArEZF08uhYzatzNslsiw8DZ5rZGuDHREH7P1cuZGZnAT3Ag6lqICLSwfK4elNeV4BKNLDIzC4CvkR0xsut7j5iZluIkvM742U2Ayvc/YjTGqtpNLBIE2uJiBypXg490Xzo7n43cHfFc9dXPN6ctYIiItK8IEeKioi0UlFmbNQVi0REmlCkKyephS4i0oSRkRHGx8cZGhpi+fLlDA0NMT4+zsjISMvrUtjZFtUpKiKdoNUzNi652RaLks8SkfAVacbG4AJ6KZ81OjrKoUOHGB0dZXh4WEFdRBZFXoOCclFrkpfFvjWanIuMVxvqxCuQiEhna3bGxjToxCsWZc2hd+IVSEREklpSOfQi5bNERJLKo+8vuIBeqHyWiEgCufX91crFLPZtsXLo7q3NZ4mINKtlF7hYLDoPXUQk0soLXIiIyCJq5QUuRERkEbXyAhciIrKIWnqBi8WgHLqISHrKoYuILAEK6CIigVBAFxEJhAK6iEggChPQe3t7MbPDN2DBYzOjt7e3zbUUESmuwpy2ePDgwYZntZQCvYiIHKkwLXQREWmOArqISCAU0EVEAqGALiISCAV0EZFAKKCLiARCAV1EJBAK6CIigShkQJ99bZbL77mcF//9xXZXRUSkYxRmpKh//gTYfCIAYyf18OjxxzF2yyDXvXRw4TIiIlJVYQK63fAK7s7sa7PsuPNC/M3X2d7Tx5WfmqLvmL5oGTN8c3vrKSJSVIVLuYw9Nsa8zwMw7/OM7R1rc41ERDpDoQL67Guz7Ni/g7n5OQDm5ufYvn+7cukiIgkkCuhmdoGZPWlm+83smhrLXGpmT5jZ42a2LUtlylvnJWqli4gk0zCHbmbdwE3A+cAM8LCZ7XT3J8qWORO4FviAux80s5OzVGbvgb2HW+clc/Nz7DmwJ0txIiJLSpJO0XOB/e7+FICZ3QZcDDxRtsx/AW5y94MA7n4gS2XuWH9HltVERIRkKZdTgWfLHs/Ez5V7J/BOM/u/ZvaQmV1QrSAzu8LMpsxsanZ2NluNRUSkqiQBvdplgiovLbQMOBP4dWADcIuZvf2IldxvdvdBdx9cuXJl2rqKiEgdSQL6DHBa2eNVwHNVltnh7nPu/iPgSaIALyIiLZIkoD8MnGlma8zsKOAyYGfFMtuBIQAz6yNKwTyVZ0VFRKS+hgHd3X8OXAXcC0wDt7v742a2xczWx4vdC7xkZk8Ak8DV7v7SYlVaRESOZO6V6fDWGBwc9KmpqbcqYkajuiRZRkQkZGb2iLsPVnutUCNFRUQkOwV0EZFAKKCLiASiMNPnQpQjr6enp6dFNRER6TyFCeiVnZ3qABURSUcpFxGRQCigi4gEQgFdRCQQCugiIoFQQBcRCYQCuohIIBTQRUQCoYAuIhIIBXQRkUAooIuIBEIBXUQkEAroIiKBUEAXEQmEArqISCAU0EVEAqGALiISCAV0EZFAKKCLiARCAV1EJBAK6CIigVBAFxEJhAK6iEggFNBFRAKhgC4iEohl7a5AJTOret/d21EdEZGOUbiArsAtIpKNUi4iIoFQQBcRCYQCuohIIBTQRUQCkSigm9kFZvakme03s2uqvH65mc2a2Z749qn8qyoiIvU0PMvFzLqBm4DzgRngYTPb6e5PVCz6NXe/ahHqKCIiCSRpoZ8L7Hf3p9z9DeA24OLFrZaIiKSVJKCfCjxb9ngmfq7SR83sMTO7w8xOq1aQmV1hZlNmNjU7O5uhuiIiUkuSgUVW5bnK0T//AEy4++tmdiXwN8CHjljJ/WbgZoA45/5Mne32AS8mqF89oZRRhDoUpYwi1KEoZRShDkUpowh1aFUZZ9R8xd3r3oD3A/eWPb4WuLbO8t3ATxuVm2C7UyqjOHUoShlFqENRyihCHYpSRhHqUIQykqRcHgbONLM1ZnYUcBmws3wBM3tH2cP1wHSCckVEJEcNUy7u/nMzuwq4l6j1fau7P25mW4i+SXYCf2Rm64GfAy8Dly9inUVEpIpEk3O5+93A3RXPXV92/1qiVEyeblYZhapDUcooQh2KUkYR6lCUMopQh7aXYXHORkREOpyG/ouIBEIBXUQkEIUL6GZ2q5kdMLN9TZRxmplNmtm0mT1uZp/OUMYKM/tnM9sbl3FDxrp0m9l3zOwfM67/tJl9N54jZypjGW+PB3x9L94n70+5/lll8/TsMbNXzOwzKcv4bLwf95nZhJmtSPcuwMw+Ha//eNLtVzuezKzXzO43sx/Ef3sylPGxuB7zZjaYYf2/jP8fj5nZXWb29gxlbI3X32Nm95nZKWnLKHvtT8zMzawvQz02m9mPy46Pi9LWwcw2xfNFPW5mf5GhDl8r2/7TZrYnQxnvNrOHSp81Mzs3QxnvMrMH48/sP5jZCXXWrxqn0h6fCzR7zmTeN+A84L3AvibKeAfw3vj+8cD3gbNTlmHAcfH95cC3gfdlqMsfA9uAf8z4Xp4G+prcp38DfCq+fxTw9ibK6gZ+ApyRYp1TgR8Bx8SPbwcuT7ndtcA+4Fiizvz/DZyZ5XgC/gK4Jr5/DfDnGcroB84CvgUMZlj/N4Fl8f0/z1iHE8ru/xEwlraM+PnTiM5ie6bRsVajHpuBP0n4f6y2/lD8/zw6fnxylvdR9voXgesz1OM+4ML4/kXAtzKU8TDwwfj+J4GtddavGqfSHp/lt8K10N39AaJTH5sp43l3fzS+/29E58VXm66gXhnu7q/GD5fHt1Q9yGa2Cvgt4JY06+UpbiGcB4wDuPsb7v6vTRT5YeCH7l5vlG81y4BjzGwZUVB+LuX6/cBD7v6au/8c+CfgI41WqnE8XUz0JUf893fSluHu0+7+ZJKK11j/vvh9ADwErMpQxitlD99Gg+Ozzmfrr4DPNVq/QRmJ1Fj/D4AvuPvr8TIHstbBzAy4FJjIUIYDpRb1iTQ4RmuUcRbwQHz/fuCjddavFadSHZ/lChfQ82Zmq4H3ELWw067bHf90OwDc7+5py/gS0QdlPu22yzhwn5k9YmZXZFj/F4BZ4H/GqZ9bzOxtTdTnMhp8WCq5+4+BG4F/AZ4nGkl8X8rt7gPOM7OTzOxYohZU1TmDEvgP7v58XLfngZMzlpOXTwLfyLKimY2Y2bPA7wHXN1q+yvrrgR+7+94s2y9zVZz+uTVViiDyTuDXzOzbZvZPZvYrTdTj14AX3P0HGdb9DPCX8f68kWynYu8jGlwJ8DESHqMVcSrz8Rl0QDez44C/Bz5T0ZpJxN3fdPd3E7WezjWztSm2/dvAAXd/JO12K3zA3d8LXAj8oZmdl3L9ZUQ/C7/s7u8Bfkb0My41i0YKrwe+nnK9HqJWxxrgFOBtZvbxNGW4+zRRauJ+4B5gL9FAto5mZsNE7+Pvsqzv7sPuflq8fqrpq+MvxmEyfBFU+DLwi8C7ib6wv5hy/WVAD/A+4Grg9rilncUGUjY4yvwB8Nl4f36W+FdtSp8k+pw+QpRGeaPRCs3GqXLBBnQzW060k/7O3e9spqw4RfEt4IIUq30AWG9mTxNNOfwhM/vbDNt+Lv57ALiLaDrjNGaAmbJfF3cQBfgsLgQedfcXUq73G8CP3H3W3eeAO4H/lHbj7j7u7u919/OIfupmaYUBvGDxdBXx37o/8ReLmX0C+G3g9zxOmDZhG3V+3tfwi0Rfsnvj43QV8KiZ/cc0hbj7C3HjZx74a7Ido3fGac5/JvpFW7dztpo4nXcJ8LW068Y+QXRsQtRoSfs+cPfvuftvuvs5RF8sP6y3fI04lfn4DDKgx9/u48C0u//3jGWsLJ15YGbHEAWl7yVd392vdfdV7r6aKE2xy91TtUrN7G1mdnzpPlFHWqqzf9z9J8CzZnZW/NSHgcqLkySVtfXzL8D7zOzY+H/zYTLM92NmJ8d/Tyf64GZtie0k+vAS/92RsZzMzOwC4E+B9e7+WsYyzix7uJ4UxyeAu3/X3U9299XxcTpD1En3k5T1KJ/L6SOkPEaB7cSzs5rZO4k67rPMWPgbwPfcfSbDuhDlzD8Y3/8QGRoMZcdoF3AdMFZn2VpxKvvxmbT3tFU3og/p88Ac0QG2MUMZ64hyz48Be+LbRSnL+GXgO3EZ+2jQa96grF8nw1kuRPnvvfHtcWA44/bfDUzF72U70JOhjGOBl4ATM9bhBqKAsw/4KvEZDSnL+D9EX0Z7gQ9nPZ6Ak4BvEn1gvwn0ZijjI/H914EXKJuRNOH6+4muM1A6PhudoVKtjL+P9+djRFNYn5q2jIrXn6bxWS7V6vFV4LtxPXYC70i5/lHA38bv5VHgQ1neB/AV4Momjot1wCPx8fVt4JwMZXya6GyV7wNfIB6NX2P9qnEq7fFZftPQfxGRQASZchERWYoU0EVEAqGALiISCAV0EZFAKKCLiARCAV1EJBAK6CIigfj/Tm6yfo9RChgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore random subspace ensemble number of features effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor n in range(1,21):\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=100, bootstrap=False, max_features=n)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901 (0.033)\n"
     ]
    }
   ],
   "source": [
    "# evaluate random subspace ensemble with knn algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the model\n",
    "model = BaggingClassifier(base_estimator=KNeighborsClassifier(), bootstrap=False, max_features=10)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
